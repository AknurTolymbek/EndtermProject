{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pet Adoption Prediction Project\n",
    "\n",
    "## Authors\n",
    "[Your Name Here]\n",
    "\n",
    "## Abstract\n",
    "This project aims to predict the likelihood of pet adoption based on various features such as pet type, breed, age, health condition, and other characteristics. We analyze a dataset of shelter pets and build machine learning models to identify key factors that influence adoption success. The insights from this analysis can help animal shelters optimize their adoption strategies and improve outcomes for pets in need of homes.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5llc6g8zqi",
   "source": "## 1. Setup",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "32gv3wksh46",
   "source": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport warnings\n\n# Set random seed for reproducibility\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\n# Configure display settings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\nprint(\"Setup complete!\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:53:07.669593Z",
     "start_time": "2025-12-05T11:53:04.916856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "qim2xampna",
   "source": "## 2. Load Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "hxkb6x3w9ce",
   "source": "# Load the dataset\ndf = pd.read_csv('pet_adoption_data.csv')\n\nprint(f\"Dataset loaded successfully!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nFirst few rows:\")\ndf.head()",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:52:23.383318Z",
     "start_time": "2025-12-05T10:52:23.363212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (2007, 13)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   PetID PetType             Breed  AgeMonths   Color    Size   WeightKg  \\\n",
       "0    500    Bird          Parakeet        131  Orange   Large   5.039768   \n",
       "1    501  Rabbit            Rabbit         73   White   Large  16.086727   \n",
       "2    502     Dog  Golden Retriever        136  Orange  Medium   2.076286   \n",
       "3    503    Bird          Parakeet         97   White   Small   3.339423   \n",
       "4    504  Rabbit            Rabbit        123    Gray   Large  20.498100   \n",
       "\n",
       "   Vaccinated  HealthCondition  TimeInShelterDays  AdoptionFee  PreviousOwner  \\\n",
       "0           1                0                 27          140              0   \n",
       "1           0                0                  8          235              0   \n",
       "2           0                0                 85          385              0   \n",
       "3           0                0                 61          217              1   \n",
       "4           0                0                 28           14              1   \n",
       "\n",
       "   AdoptionLikelihood  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>PetType</th>\n",
       "      <th>Breed</th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>Color</th>\n",
       "      <th>Size</th>\n",
       "      <th>WeightKg</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>HealthCondition</th>\n",
       "      <th>TimeInShelterDays</th>\n",
       "      <th>AdoptionFee</th>\n",
       "      <th>PreviousOwner</th>\n",
       "      <th>AdoptionLikelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Parakeet</td>\n",
       "      <td>131</td>\n",
       "      <td>Orange</td>\n",
       "      <td>Large</td>\n",
       "      <td>5.039768</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501</td>\n",
       "      <td>Rabbit</td>\n",
       "      <td>Rabbit</td>\n",
       "      <td>73</td>\n",
       "      <td>White</td>\n",
       "      <td>Large</td>\n",
       "      <td>16.086727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Golden Retriever</td>\n",
       "      <td>136</td>\n",
       "      <td>Orange</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2.076286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Parakeet</td>\n",
       "      <td>97</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>3.339423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>Rabbit</td>\n",
       "      <td>Rabbit</td>\n",
       "      <td>123</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Large</td>\n",
       "      <td>20.498100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "2hih54sznrg",
   "source": "# Dataset information\nprint(\"Dataset Information:\")\nprint(\"=\"*50)\ndf.info()\nprint(\"\\n\" + \"=\"*50)\nprint(\"\\nDataset Statistics:\")\ndf.describe()",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:52:34.188563Z",
     "start_time": "2025-12-05T10:52:34.171258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "==================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2007 entries, 0 to 2006\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   PetID               2007 non-null   int64  \n",
      " 1   PetType             2007 non-null   object \n",
      " 2   Breed               2007 non-null   object \n",
      " 3   AgeMonths           2007 non-null   int64  \n",
      " 4   Color               2007 non-null   object \n",
      " 5   Size                2007 non-null   object \n",
      " 6   WeightKg            2007 non-null   float64\n",
      " 7   Vaccinated          2007 non-null   int64  \n",
      " 8   HealthCondition     2007 non-null   int64  \n",
      " 9   TimeInShelterDays   2007 non-null   int64  \n",
      " 10  AdoptionFee         2007 non-null   int64  \n",
      " 11  PreviousOwner       2007 non-null   int64  \n",
      " 12  AdoptionLikelihood  2007 non-null   int64  \n",
      "dtypes: float64(1), int64(8), object(4)\n",
      "memory usage: 204.0+ KB\n",
      "\n",
      "==================================================\n",
      "\n",
      "Dataset Statistics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "             PetID    AgeMonths     WeightKg   Vaccinated  HealthCondition  \\\n",
       "count  2007.000000  2007.000000  2007.000000  2007.000000      2007.000000   \n",
       "mean   1503.000000    92.279522    15.705776     0.701046         0.196313   \n",
       "std     579.515315    52.148363     8.327749     0.457914         0.397307   \n",
       "min     500.000000     1.000000     1.018198     0.000000         0.000000   \n",
       "25%    1001.500000    48.000000     8.730396     0.000000         0.000000   \n",
       "50%    1503.000000    94.000000    15.925416     1.000000         0.000000   \n",
       "75%    2004.500000   138.000000    22.737180     1.000000         0.000000   \n",
       "max    2506.000000   179.000000    29.995628     1.000000         1.000000   \n",
       "\n",
       "       TimeInShelterDays  AdoptionFee  PreviousOwner  AdoptionLikelihood  \n",
       "count        2007.000000  2007.000000    2007.000000         2007.000000  \n",
       "mean           43.974091   249.142003       0.301943            0.328351  \n",
       "std            25.740253   142.887040       0.459215            0.469730  \n",
       "min             1.000000     0.000000       0.000000            0.000000  \n",
       "25%            21.000000   127.000000       0.000000            0.000000  \n",
       "50%            45.000000   242.000000       0.000000            0.000000  \n",
       "75%            66.000000   375.000000       1.000000            1.000000  \n",
       "max            89.000000   499.000000       1.000000            1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>WeightKg</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>HealthCondition</th>\n",
       "      <th>TimeInShelterDays</th>\n",
       "      <th>AdoptionFee</th>\n",
       "      <th>PreviousOwner</th>\n",
       "      <th>AdoptionLikelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1503.000000</td>\n",
       "      <td>92.279522</td>\n",
       "      <td>15.705776</td>\n",
       "      <td>0.701046</td>\n",
       "      <td>0.196313</td>\n",
       "      <td>43.974091</td>\n",
       "      <td>249.142003</td>\n",
       "      <td>0.301943</td>\n",
       "      <td>0.328351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>579.515315</td>\n",
       "      <td>52.148363</td>\n",
       "      <td>8.327749</td>\n",
       "      <td>0.457914</td>\n",
       "      <td>0.397307</td>\n",
       "      <td>25.740253</td>\n",
       "      <td>142.887040</td>\n",
       "      <td>0.459215</td>\n",
       "      <td>0.469730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.018198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1001.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>8.730396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1503.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>15.925416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2004.500000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>22.737180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2506.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>29.995628</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "w6xj62tvu7",
   "source": "### Target Variable: AdoptionLikelihood\n\n**AdoptionLikelihood** is our target variable (dependent variable) that we want to predict.\n\n- **Type:** Binary Classification (0 or 1)\n- **Meaning:**\n  - **0:** Pet was **NOT adopted** - remained in the shelter\n  - **1:** Pet was **adopted** - successfully found a home\n\n- **Distribution:**\n  - **Not Adopted (0):** 1,348 pets (67.2%)\n  - **Adopted (1):** 659 pets (32.8%)\n\n- **Class Imbalance:** The dataset shows class imbalance with approximately **2:1 ratio** (more pets not adopted than adopted). This is important to consider when building machine learning models, as we may need to:\n  - Use stratified sampling\n  - Apply class weights\n  - Use appropriate evaluation metrics (precision, recall, F1-score, AUC-ROC)\n  - Consider oversampling/undersampling techniques (SMOTE, etc.)\n\n**Why is this important?**\nUnderstanding which factors contribute to successful adoptions can help shelters:\n- Identify pets that may need extra attention or marketing\n- Optimize adoption fees and vaccination programs\n- Improve shelter conditions and reduce time-to-adoption\n- Make data-driven decisions to increase overall adoption rates",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "q816aiwejd",
   "source": "### Variable Descriptions\n\n| Variable | Type | Description | Values/Range |\n|----------|------|-------------|--------------|\n| **PetID** | Numerical (ID) | Unique identifier for each pet | 500 - 2506 |\n| **PetType** | Categorical | Type of animal | Cat, Dog, Bird, Rabbit |\n| **Breed** | Categorical | Specific breed of the pet | Golden Retriever, Persian, Parakeet, Rabbit, Labrador, Poodle |\n| **AgeMonths** | Numerical | Age of the pet in months | 1 - 179 months |\n| **Color** | Categorical | Primary color of the pet | White, Orange, Gray, Black, Brown |\n| **Size** | Categorical (Ordinal) | Physical size category | Small, Medium, Large |\n| **WeightKg** | Numerical | Weight of the pet in kilograms | 1.02 - 30.0 kg |\n| **Vaccinated** | Binary | Vaccination status | 0 = Not vaccinated, 1 = Vaccinated |\n| **HealthCondition** | Binary | Overall health status | 0 = Healthy, 1 = Has health issues |\n| **TimeInShelterDays** | Numerical | Number of days spent in the shelter | 1 - 89 days |\n| **AdoptionFee** | Numerical | Fee required to adopt the pet (in currency units) | 0 - 499 |\n| **PreviousOwner** | Binary | Whether the pet had a previous owner | 0 = No previous owner, 1 = Had previous owner |\n| **AdoptionLikelihood** | Binary (Target) | Whether the pet was adopted | 0 = Not adopted, 1 = Adopted |",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "83rsqcqa4c6",
   "source": "## 3. Data Description\n\n### Dataset Overview\n\nThis dataset contains information about **2,007 shelter pets** with **13 variables** (features). The primary goal is to predict the **likelihood of pet adoption** based on various characteristics such as pet type, physical attributes, health status, and shelter conditions.\n\n**Task Type:** Binary Classification\n- **Objective:** Predict whether a pet will be adopted (1) or not (0)\n- **Use Case:** Help animal shelters identify factors that influence adoption success and optimize their strategies to improve adoption rates",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "jvvjx0oz9ee",
   "source": "## 4. Exploratory Data Analysis (EDA)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "ej643yedd8s",
   "source": "### 4.1 Target Distribution",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "t55oiqqnw0h",
   "source": "# Target variable distribution analysis\nprint(\"=\"*60)\nprint(\"TARGET VARIABLE: AdoptionLikelihood\")\nprint(\"=\"*60)\n\n# Class counts\nprint(\"\\n1. Class Distribution:\")\nprint(\"-\" * 60)\ntarget_counts = df['AdoptionLikelihood'].value_counts().sort_index()\ntarget_pct = df['AdoptionLikelihood'].value_counts(normalize=True).sort_index() * 100\n\nfor label, count in target_counts.items():\n    pct = target_pct[label]\n    status = \"Not Adopted\" if label == 0 else \"Adopted\"\n    print(f\"   Class {label} ({status:12s}): {count:4d} pets ({pct:5.2f}%)\")\n\n# Class balance ratio\nratio = target_counts[0] / target_counts[1]\nprint(f\"\\n   Class Imbalance Ratio: {ratio:.2f}:1 (Not Adopted : Adopted)\")\n\n# Visualizations\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n# Bar plot\ncolors_bar = ['#e74c3c', '#2ecc71']\nbars = axes[0].bar(target_counts.index, target_counts.values, color=colors_bar, \n                    edgecolor='black', linewidth=1.5, alpha=0.8)\naxes[0].set_xlabel('Adoption Likelihood', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Number of Pets', fontsize=12, fontweight='bold')\naxes[0].set_title('Target Distribution - Count', fontsize=14, fontweight='bold', pad=15)\naxes[0].set_xticks([0, 1])\naxes[0].set_xticklabels(['Not Adopted (0)', 'Adopted (1)'])\naxes[0].grid(axis='y', alpha=0.3, linestyle='--')\n\n# Add value labels on bars\nfor bar in bars:\n    height = bar.get_height()\n    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n                f'{int(height)}',\n                ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# Pie chart\ncolors_pie = ['#e74c3c', '#2ecc71']\nexplode = (0.05, 0.05)\nwedges, texts, autotexts = axes[1].pie(target_counts.values, \n                                         labels=['Not Adopted', 'Adopted'],\n                                         autopct='%1.1f%%',\n                                         colors=colors_pie,\n                                         explode=explode,\n                                         startangle=90,\n                                         textprops={'fontsize': 11, 'fontweight': 'bold'})\naxes[1].set_title('Target Distribution - Percentage', fontsize=14, fontweight='bold', pad=15)\n\n# Percentage bar plot\nbars2 = axes[2].barh(['Not Adopted', 'Adopted'], target_pct.values[::-1], \n                     color=colors_bar[::-1], edgecolor='black', linewidth=1.5, alpha=0.8)\naxes[2].set_xlabel('Percentage (%)', fontsize=12, fontweight='bold')\naxes[2].set_title('Class Balance', fontsize=14, fontweight='bold', pad=15)\naxes[2].grid(axis='x', alpha=0.3, linestyle='--')\n\n# Add percentage labels\nfor i, bar in enumerate(bars2):\n    width = bar.get_width()\n    axes[2].text(width, bar.get_y() + bar.get_height()/2.,\n                f'{width:.1f}%',\n                ha='left', va='center', fontsize=11, fontweight='bold', \n                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Key Observations:\")\nprint(\"-\" * 60)\nprint(f\"âœ“ Dataset is IMBALANCED - {ratio:.2f}x more 'Not Adopted' than 'Adopted'\")\nprint(f\"âœ“ This imbalance should be addressed during modeling\")\nprint(\"=\"*60)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:52:45.014484Z",
     "start_time": "2025-12-05T10:52:45.005570Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ktq86iy5ui",
   "source": "### 4.2 Univariate Analysis\n\nAnalysis of individual features to understand their distributions and characteristics.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "1qzqi306m8k",
   "source": "#### 4.2.1 Numerical Features Distribution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:57:36.750492Z",
     "start_time": "2025-12-05T10:57:36.681022Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "tw8lbv4531r",
   "source": "# Analyze numerical features\nnumerical_features = ['AgeMonths', 'WeightKg', 'TimeInShelterDays', 'AdoptionFee']\n\nprint(\"=\"*70)\nprint(\"NUMERICAL FEATURES ANALYSIS\")\nprint(\"=\"*70)\n\n# Statistical summary\nprint(\"\\nDescriptive Statistics:\")\nprint(\"-\"*70)\nstats_df = df[numerical_features].describe().T\nstats_df['skewness'] = df[numerical_features].skew()\nstats_df['kurtosis'] = df[numerical_features].kurtosis()\nprint(stats_df.round(2))\n\n# Visualizations - Histograms with KDE\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\naxes = axes.ravel()\n\nfor idx, col in enumerate(numerical_features):\n    # Histogram with KDE\n    axes[idx].hist(df[col], bins=30, color='steelblue', edgecolor='black', \n                   alpha=0.7, density=True, label='Histogram')\n    \n    # KDE overlay\n    df[col].plot(kind='kde', ax=axes[idx], color='red', linewidth=2, \n                 label='KDE', secondary_y=False)\n    \n    # Statistics lines\n    mean_val = df[col].mean()\n    median_val = df[col].median()\n    axes[idx].axvline(mean_val, color='darkgreen', linestyle='--', \n                      linewidth=2, label=f'Mean: {mean_val:.2f}')\n    axes[idx].axvline(median_val, color='orange', linestyle='--', \n                      linewidth=2, label=f'Median: {median_val:.2f}')\n    \n    axes[idx].set_title(f'{col} Distribution', fontsize=13, fontweight='bold', pad=10)\n    axes[idx].set_xlabel(col, fontsize=11, fontweight='bold')\n    axes[idx].set_ylabel('Density / Frequency', fontsize=11, fontweight='bold')\n    axes[idx].legend(loc='upper right', fontsize=9)\n    axes[idx].grid(alpha=0.3, linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Key Observations:\")\nprint(\"-\"*70)\nfor col in numerical_features:\n    skew = df[col].skew()\n    if abs(skew) < 0.5:\n        skew_type = \"approximately symmetric\"\n    elif skew > 0:\n        skew_type = \"right-skewed (positive skew)\"\n    else:\n        skew_type = \"left-skewed (negative skew)\"\n    print(f\"âœ“ {col}: {skew_type} (skewness = {skew:.2f})\")\nprint(\"=\"*70)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "ray42cijul",
   "source": "#### 4.2.2 Numerical Features - Boxplots",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:57:43.371213Z",
     "start_time": "2025-12-05T10:57:43.221614Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0kf2t7mywroc",
   "source": "# Boxplots to identify outliers\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\naxes = axes.ravel()\n\nfor idx, col in enumerate(numerical_features):\n    # Create boxplot\n    bp = axes[idx].boxplot([df[col]], vert=True, patch_artist=True,\n                           labels=[col],\n                           boxprops=dict(facecolor='lightblue', color='navy', linewidth=2),\n                           whiskerprops=dict(color='navy', linewidth=1.5),\n                           capprops=dict(color='navy', linewidth=1.5),\n                           medianprops=dict(color='red', linewidth=2),\n                           flierprops=dict(marker='o', markerfacecolor='red', \n                                          markersize=5, markeredgecolor='darkred'))\n    \n    # Add mean marker\n    mean_val = df[col].mean()\n    axes[idx].plot(1, mean_val, marker='D', markersize=10, \n                   color='green', label=f'Mean: {mean_val:.2f}')\n    \n    axes[idx].set_title(f'{col} - Boxplot', fontsize=13, fontweight='bold', pad=10)\n    axes[idx].set_ylabel('Value', fontsize=11, fontweight='bold')\n    axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n    axes[idx].legend(loc='upper right')\n    \n    # Calculate outliers using IQR\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n    \n    # Add text with outlier info\n    outlier_text = f'Outliers: {len(outliers)} ({len(outliers)/len(df)*100:.1f}%)'\n    axes[idx].text(0.98, 0.02, outlier_text, transform=axes[idx].transAxes,\n                   fontsize=10, verticalalignment='bottom', horizontalalignment='right',\n                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\nplt.tight_layout()\nplt.show()",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "jzow2f17iu",
   "source": "#### 4.2.3 Categorical Features Distribution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:57:51.414839Z",
     "start_time": "2025-12-05T10:57:51.146834Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1z9j3b4hban",
   "source": "# Analyze categorical features\ncategorical_features = ['PetType', 'Breed', 'Color', 'Size']\n\nprint(\"=\"*70)\nprint(\"CATEGORICAL FEATURES ANALYSIS\")\nprint(\"=\"*70)\n\n# Count and percentage for each feature\nfor feature in categorical_features:\n    print(f\"\\n{feature}:\")\n    print(\"-\"*70)\n    counts = df[feature].value_counts()\n    percentages = df[feature].value_counts(normalize=True) * 100\n    summary = pd.DataFrame({\n        'Count': counts,\n        'Percentage': percentages\n    })\n    print(summary.round(2))\n\n# Visualizations\nfig, axes = plt.subplots(2, 2, figsize=(18, 12))\naxes = axes.ravel()\n\ncolors_palette = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6', '#1abc9c']\n\nfor idx, col in enumerate(categorical_features):\n    value_counts = df[col].value_counts()\n    \n    # Create bar chart\n    bars = axes[idx].bar(range(len(value_counts)), value_counts.values, \n                         color=colors_palette[:len(value_counts)],\n                         edgecolor='black', linewidth=1.5, alpha=0.8)\n    \n    axes[idx].set_xlabel(col, fontsize=12, fontweight='bold')\n    axes[idx].set_ylabel('Count', fontsize=12, fontweight='bold')\n    axes[idx].set_title(f'{col} Distribution', fontsize=14, fontweight='bold', pad=10)\n    axes[idx].set_xticks(range(len(value_counts)))\n    axes[idx].set_xticklabels(value_counts.index, rotation=45, ha='right')\n    axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n    \n    # Add value labels on bars\n    for bar in bars:\n        height = bar.get_height()\n        axes[idx].text(bar.get_x() + bar.get_width()/2., height,\n                      f'{int(height)}',\n                      ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "nkuaxt6ckvo",
   "source": "#### 4.2.4 Binary Features Distribution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:03:04.830603Z",
     "start_time": "2025-12-05T11:03:04.714630Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ww14xacs64a",
   "source": "# Analyze binary features\nbinary_features = ['Vaccinated', 'HealthCondition', 'PreviousOwner']\nbinary_labels = {\n    'Vaccinated': {0: 'Not Vaccinated', 1: 'Vaccinated'},\n    'HealthCondition': {0: 'Healthy', 1: 'Has Issues'},\n    'PreviousOwner': {0: 'No Previous Owner', 1: 'Had Previous Owner'}\n}\n\nprint(\"=\"*70)\nprint(\"BINARY FEATURES ANALYSIS\")\nprint(\"=\"*70)\n\n# Statistics\nfor feature in binary_features:\n    print(f\"\\n{feature}:\")\n    print(\"-\"*70)\n    counts = df[feature].value_counts().sort_index()\n    percentages = df[feature].value_counts(normalize=True).sort_index() * 100\n    \n    for val in [0, 1]:\n        label = binary_labels[feature][val]\n        print(f\"   {val} ({label:20s}): {counts[val]:4d} ({percentages[val]:5.2f}%)\")\n\n# Visualizations\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\ncolors = ['#e74c3c', '#2ecc71']\n\nfor idx, feature in enumerate(binary_features):\n    counts = df[feature].value_counts().sort_index()\n    labels = [binary_labels[feature][0], binary_labels[feature][1]]\n    \n    # Bar chart\n    bars = axes[idx].bar(labels, counts.values, color=colors,\n                         edgecolor='black', linewidth=1.5, alpha=0.8)\n    \n    axes[idx].set_xlabel(feature, fontsize=12, fontweight='bold')\n    axes[idx].set_ylabel('Count', fontsize=12, fontweight='bold')\n    axes[idx].set_title(f'{feature} Distribution', fontsize=14, fontweight='bold', pad=10)\n    axes[idx].tick_params(axis='x', rotation=15)\n    axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n    \n    # Add percentage labels\n    for bar, count in zip(bars, counts.values):\n        height = bar.get_height()\n        pct = (count / len(df)) * 100\n        axes[idx].text(bar.get_x() + bar.get_width()/2., height,\n                      f'{int(count)}\\n({pct:.1f}%)',\n                      ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "j8awpd8k8g",
   "source": "### 4.3 Bivariate Analysis\n\nAnalyzing relationships between features and the target variable (AdoptionLikelihood).",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:03:11.737686Z",
     "start_time": "2025-12-05T11:03:11.493450Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bvv4qob3lga",
   "source": "#### 4.3.1 Adoption Rate by Categorical Features",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:03:17.909301Z",
     "start_time": "2025-12-05T11:03:17.779941Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0tx4hzp1zq8",
   "source": "# Boxplots for numerical features grouped by target\nnumerical_features = ['AgeMonths', 'WeightKg', 'TimeInShelterDays', 'AdoptionFee']\n\nprint(\"=\"*70)\nprint(\"NUMERICAL FEATURES BY ADOPTION OUTCOME\")\nprint(\"=\"*70)\n\n# Statistical comparison\nfor feature in numerical_features:\n    print(f\"\\n{feature}:\")\n    print(\"-\"*70)\n    stats_by_target = df.groupby('AdoptionLikelihood')[feature].describe()\n    print(stats_by_target.round(2))\n\n# Visualizations\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\naxes = axes.ravel()\n\ncolors = {0: '#e74c3c', 1: '#2ecc71'}\n\nfor idx, col in enumerate(numerical_features):\n    # Prepare data\n    not_adopted = df[df['AdoptionLikelihood'] == 0][col]\n    adopted = df[df['AdoptionLikelihood'] == 1][col]\n    \n    # Create boxplot\n    bp = axes[idx].boxplot([not_adopted, adopted], \n                           labels=['Not Adopted (0)', 'Adopted (1)'],\n                           patch_artist=True,\n                           boxprops=dict(linewidth=2),\n                           whiskerprops=dict(linewidth=1.5),\n                           capprops=dict(linewidth=1.5),\n                           medianprops=dict(color='darkblue', linewidth=2),\n                           flierprops=dict(marker='o', markersize=4, alpha=0.5))\n    \n    # Color the boxes\n    for patch, adoption_status in zip(bp['boxes'], [0, 1]):\n        patch.set_facecolor(colors[adoption_status])\n        patch.set_alpha(0.7)\n    \n    axes[idx].set_title(f'{col} by Adoption Outcome', fontsize=13, fontweight='bold', pad=10)\n    axes[idx].set_ylabel(col, fontsize=11, fontweight='bold')\n    axes[idx].set_xlabel('Adoption Outcome', fontsize=11, fontweight='bold')\n    axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n    \n    # Add mean markers\n    mean_not_adopted = not_adopted.mean()\n    mean_adopted = adopted.mean()\n    axes[idx].plot(1, mean_not_adopted, 'D', markersize=10, color='darkred', \n                   label=f'Mean Not Adopted: {mean_not_adopted:.1f}')\n    axes[idx].plot(2, mean_adopted, 'D', markersize=10, color='darkgreen',\n                   label=f'Mean Adopted: {mean_adopted:.1f}')\n    axes[idx].legend(loc='best', fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ifu46f4k7ye",
   "source": "# Missing values analysis\nprint(\"=\"*70)\nprint(\"MISSING VALUES ANALYSIS\")\nprint(\"=\"*70)\n\nmissing_counts = df.isnull().sum()\nmissing_pct = (df.isnull().sum() / len(df)) * 100\n\nmissing_df = pd.DataFrame({\n    'Missing Count': missing_counts,\n    'Percentage (%)': missing_pct\n}).sort_values('Missing Count', ascending=False)\n\nprint(\"\\nMissing Values Summary:\")\nprint(\"-\"*70)\nif missing_df['Missing Count'].sum() == 0:\n    print(\"âœ“ NO MISSING VALUES FOUND - Dataset is complete!\")\nelse:\n    print(missing_df[missing_df['Missing Count'] > 0])\n\n# Visualization\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Missing values bar chart\nif missing_df['Missing Count'].sum() > 0:\n    missing_features = missing_df[missing_df['Missing Count'] > 0]\n    axes[0].bar(range(len(missing_features)), missing_features['Percentage (%)'].values,\n                color='#e74c3c', edgecolor='black', linewidth=1.5, alpha=0.8)\n    axes[0].set_xticks(range(len(missing_features)))\n    axes[0].set_xticklabels(missing_features.index, rotation=45, ha='right')\n    axes[0].set_ylabel('Missing Percentage (%)', fontsize=12, fontweight='bold')\n    axes[0].set_title('Missing Values by Feature', fontsize=14, fontweight='bold', pad=10)\n    axes[0].grid(axis='y', alpha=0.3, linestyle='--')\nelse:\n    axes[0].text(0.5, 0.5, 'No Missing Values\\nâœ“ Complete Dataset', \n                ha='center', va='center', fontsize=16, fontweight='bold',\n                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n    axes[0].axis('off')\n\n# Heatmap showing completeness\ncomplete_matrix = df.notnull().astype(int)\nsns.heatmap(complete_matrix.T, cmap='RdYlGn', cbar_kws={'label': 'Complete (1) / Missing (0)'},\n            yticklabels=df.columns, ax=axes[1], xticklabels=False)\naxes[1].set_title('Data Completeness Heatmap', fontsize=14, fontweight='bold', pad=10)\naxes[1].set_xlabel('Samples', fontsize=12, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Outliers analysis\nprint(\"\\n\" + \"=\"*70)\nprint(\"OUTLIERS ANALYSIS (IQR Method)\")\nprint(\"=\"*70)\n\nnumerical_features = ['AgeMonths', 'WeightKg', 'TimeInShelterDays', 'AdoptionFee']\n\noutlier_summary = []\n\nfor feature in numerical_features:\n    Q1 = df[feature].quantile(0.25)\n    Q3 = df[feature].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    \n    outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n    outlier_count = len(outliers)\n    outlier_pct = (outlier_count / len(df)) * 100\n    \n    outlier_summary.append({\n        'Feature': feature,\n        'Q1': Q1,\n        'Q3': Q3,\n        'IQR': IQR,\n        'Lower Bound': lower_bound,\n        'Upper Bound': upper_bound,\n        'Outlier Count': outlier_count,\n        'Outlier %': outlier_pct\n    })\n\noutlier_df = pd.DataFrame(outlier_summary)\n\nprint(\"\\nOutlier Detection Summary:\")\nprint(\"-\"*70)\nprint(outlier_df.round(2))\n\n# Visualization\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\naxes = axes.ravel()\n\nfor idx, feature in enumerate(numerical_features):\n    # Calculate outliers\n    Q1 = df[feature].quantile(0.25)\n    Q3 = df[feature].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    \n    # Separate outliers and normal values\n    normal_mask = (df[feature] >= lower_bound) & (df[feature] <= upper_bound)\n    outlier_mask = ~normal_mask\n    \n    # Scatter plot\n    axes[idx].scatter(df[normal_mask].index, df[normal_mask][feature],\n                     alpha=0.5, s=20, color='steelblue', label='Normal')\n    axes[idx].scatter(df[outlier_mask].index, df[outlier_mask][feature],\n                     alpha=0.7, s=30, color='red', marker='x', label='Outliers')\n    \n    # Add boundary lines\n    axes[idx].axhline(y=lower_bound, color='orange', linestyle='--', \n                     linewidth=2, label=f'Lower Bound: {lower_bound:.1f}')\n    axes[idx].axhline(y=upper_bound, color='green', linestyle='--', \n                     linewidth=2, label=f'Upper Bound: {upper_bound:.1f}')\n    \n    axes[idx].set_title(f'{feature} - Outlier Detection', fontsize=13, fontweight='bold', pad=10)\n    axes[idx].set_xlabel('Sample Index', fontsize=11, fontweight='bold')\n    axes[idx].set_ylabel(feature, fontsize=11, fontweight='bold')\n    axes[idx].legend(loc='best', fontsize=9)\n    axes[idx].grid(alpha=0.3, linestyle='--')\n    \n    # Add text box with outlier count\n    outlier_count = outlier_mask.sum()\n    outlier_pct = (outlier_count / len(df)) * 100\n    textstr = f'Outliers: {outlier_count}\\n({outlier_pct:.1f}%)'\n    axes[idx].text(0.02, 0.98, textstr, transform=axes[idx].transAxes,\n                  fontsize=10, verticalalignment='top',\n                  bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Summary:\")\nprint(\"-\"*70)\ntotal_outliers = outlier_df['Outlier Count'].sum()\nprint(f\"âœ“ Total outliers across all numerical features: {total_outliers}\")\nprint(f\"âœ“ Average outlier percentage: {outlier_df['Outlier %'].mean():.2f}%\")\nif total_outliers == 0:\n    print(\"âœ“ No outliers detected - data is well-distributed!\")\nelse:\n    print(\"âœ“ Outliers detected but kept for analysis - consider handling in preprocessing\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "pdbvhnav9wh",
   "source": "# Key Insights Summary\nprint(\"=\"*80)\nprint(\" \"*25 + \"KEY INSIGHTS FROM EDA\")\nprint(\"=\"*80)\n\n# 1. Dataset Overview\nprint(\"\\n1. DATASET OVERVIEW\")\nprint(\"-\"*80)\nprint(f\"   â€¢ Total samples: {len(df):,}\")\nprint(f\"   â€¢ Total features: {df.shape[1]}\")\nprint(f\"   â€¢ Numerical features: {len(df.select_dtypes(include=[np.number]).columns)}\")\nprint(f\"   â€¢ Categorical features: {len(df.select_dtypes(include=['object']).columns)}\")\nprint(f\"   â€¢ Missing values: {df.isnull().sum().sum()} (Dataset is complete!)\")\n\n# 2. Target Variable\nprint(\"\\n2. TARGET VARIABLE (AdoptionLikelihood)\")\nprint(\"-\"*80)\nadopted = df['AdoptionLikelihood'].sum()\nnot_adopted = len(df) - adopted\nadoption_rate = df['AdoptionLikelihood'].mean()\nimbalance_ratio = not_adopted / adopted\n\nprint(f\"   â€¢ Adoption rate: {adoption_rate:.1%}\")\nprint(f\"   â€¢ Adopted: {adopted} pets ({adopted/len(df)*100:.1f}%)\")\nprint(f\"   â€¢ Not adopted: {not_adopted} pets ({not_adopted/len(df)*100:.1f}%)\")\nprint(f\"   â€¢ Class imbalance ratio: {imbalance_ratio:.2f}:1 (Not Adopted : Adopted)\")\nprint(f\"   âš  ACTION NEEDED: Address class imbalance in modeling (use SMOTE, class weights, etc.)\")\n\n# 3. Feature Analysis\nprint(\"\\n3. FEATURE CHARACTERISTICS\")\nprint(\"-\"*80)\n\n# Numerical features\nnumerical_features = ['AgeMonths', 'WeightKg', 'TimeInShelterDays', 'AdoptionFee']\nprint(\"   Numerical Features:\")\nfor feature in numerical_features:\n    mean_val = df[feature].mean()\n    median_val = df[feature].median()\n    std_val = df[feature].std()\n    skew_val = df[feature].skew()\n    print(f\"   â€¢ {feature:20s}: Mean={mean_val:6.1f}, Median={median_val:6.1f}, Std={std_val:6.1f}, Skew={skew_val:5.2f}\")\n\n# Categorical features\nprint(\"\\n   Categorical Features:\")\ncategorical_features = ['PetType', 'Breed', 'Color', 'Size']\nfor feature in categorical_features:\n    n_unique = df[feature].nunique()\n    most_common = df[feature].value_counts().index[0]\n    most_common_pct = df[feature].value_counts(normalize=True).iloc[0] * 100\n    print(f\"   â€¢ {feature:20s}: {n_unique} unique values (Most common: {most_common}, {most_common_pct:.1f}%)\")\n\n# 4. Correlation with Target\nprint(\"\\n4. CORRELATION WITH TARGET\")\nprint(\"-\"*80)\nnumerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\ncorrelation_matrix = df[numerical_cols].corr()\ntarget_corr = correlation_matrix['AdoptionLikelihood'].drop('AdoptionLikelihood').sort_values(ascending=False)\n\nprint(\"   Top features correlated with adoption:\")\nfor idx, (feature, corr_value) in enumerate(target_corr.head(5).items(), 1):\n    direction = \"positively\" if corr_value > 0 else \"negatively\"\n    print(f\"   {idx}. {feature:20s}: {corr_value:+.3f} ({direction} correlated)\")\n\n# 5. Adoption Rates by Features\nprint(\"\\n5. ADOPTION RATES BY KEY FEATURES\")\nprint(\"-\"*80)\n\n# Best adoption rates\nprint(\"   Features with HIGHEST adoption rates:\")\nfeatures_to_check = ['PetType', 'Size', 'Vaccinated']\nfor feature in features_to_check:\n    best_category = df.groupby(feature)['AdoptionLikelihood'].mean().idxmax()\n    best_rate = df.groupby(feature)['AdoptionLikelihood'].mean().max()\n    print(f\"   â€¢ {feature:20s}: {best_category} ({best_rate:.1%} adoption rate)\")\n\nprint(\"\\n   Features with LOWEST adoption rates:\")\nfor feature in features_to_check:\n    worst_category = df.groupby(feature)['AdoptionLikelihood'].mean().idxmin()\n    worst_rate = df.groupby(feature)['AdoptionLikelihood'].mean().min()\n    print(f\"   â€¢ {feature:20s}: {worst_category} ({worst_rate:.1%} adoption rate)\")\n\n# 6. Data Quality\nprint(\"\\n6. DATA QUALITY\")\nprint(\"-\"*80)\nprint(f\"   â€¢ Missing values: âœ“ None (100% complete)\")\nprint(f\"   â€¢ Duplicate rows: âœ“ None\")\n\n# Check outliers\noutlier_counts = []\nfor feature in numerical_features:\n    Q1 = df[feature].quantile(0.25)\n    Q3 = df[feature].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n    outlier_counts.append(len(outliers))\n\ntotal_outliers = sum(outlier_counts)\nif total_outliers == 0:\n    print(f\"   â€¢ Outliers: âœ“ None detected\")\nelse:\n    print(f\"   â€¢ Outliers: {total_outliers} detected across numerical features (kept for analysis)\")\n\n# 7. Key Recommendations\nprint(\"\\n7. KEY RECOMMENDATIONS FOR MODELING\")\nprint(\"-\"*80)\nprint(\"   1. âš  Address class imbalance (67% not adopted vs 33% adopted)\")\nprint(\"      â†’ Use techniques like SMOTE, class weights, or stratified sampling\")\nprint(\"   \")\nprint(\"   2. âœ“ No missing values - dataset is ready for modeling\")\nprint(\"   \")\nprint(\"   3. ðŸ“Š Focus on important features:\")\n\n# Get top features\ntop_features_list = target_corr.head(3).index.tolist()\nfor idx, feature in enumerate(top_features_list, 1):\n    print(f\"      â†’ Feature {idx}: {feature} (correlation: {target_corr[feature]:+.3f})\")\n\nprint(\"   \")\nprint(\"   4. ðŸ” Consider feature engineering:\")\nprint(\"      â†’ Age categories (Young/Adult/Senior)\")\nprint(\"      â†’ Combined health scores (Vaccination + Health Condition)\")\nprint(\"      â†’ Time-based features (days in shelter categories)\")\nprint(\"   \")\nprint(\"   5. ðŸ“ˆ Evaluation metrics to use:\")\nprint(\"      â†’ Precision, Recall, F1-Score (due to imbalanced classes)\")\nprint(\"      â†’ ROC-AUC curve\")\nprint(\"      â†’ Confusion matrix analysis\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\" \"*20 + \"END OF EXPLORATORY DATA ANALYSIS\")\nprint(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ppz5gz84zz",
   "source": "### 4.6 Key Insights Summary\n\nThis section summarizes the most important findings from our exploratory data analysis.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "h6qkoydg154",
   "source": "### 4.5 Missing Values and Outliers Analysis",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0mole98z09le",
   "source": "# Correlation matrix for all numerical features\nprint(\"=\"*70)\nprint(\"CORRELATION ANALYSIS\")\nprint(\"=\"*70)\n\n# Select numerical columns\nnumerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n\n# Calculate correlation matrix\ncorrelation_matrix = df[numerical_cols].corr()\n\nprint(\"\\nCorrelation with Target Variable (AdoptionLikelihood):\")\nprint(\"-\"*70)\ntarget_corr = correlation_matrix['AdoptionLikelihood'].sort_values(ascending=False)\nfor feature, corr_value in target_corr.items():\n    if feature != 'AdoptionLikelihood':\n        if abs(corr_value) > 0.3:\n            strength = \"Strong\"\n        elif abs(corr_value) > 0.1:\n            strength = \"Moderate\"\n        else:\n            strength = \"Weak\"\n        print(f\"{feature:25s}: {corr_value:6.3f} ({strength})\")\n\n# Visualization - Heatmap\nfig, axes = plt.subplots(1, 2, figsize=(20, 8))\n\n# Full correlation matrix\nsns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n            ax=axes[0], vmin=-1, vmax=1)\naxes[0].set_title('Correlation Matrix - All Numerical Features', \n                  fontsize=14, fontweight='bold', pad=15)\n\n# Correlation with target only\ntarget_corr_df = target_corr.drop('AdoptionLikelihood').to_frame()\ntarget_corr_df.columns = ['Correlation']\nsns.heatmap(target_corr_df, annot=True, fmt='.3f', cmap='RdYlGn', \n            center=0, linewidths=1, cbar_kws={\"shrink\": 0.8},\n            ax=axes[1], vmin=-1, vmax=1)\naxes[1].set_title('Correlation with Target (AdoptionLikelihood)', \n                  fontsize=14, fontweight='bold', pad=15)\n\nplt.tight_layout()\nplt.show()\n\n# Additional: Scatter plots for top correlated features\ntop_features = target_corr.drop('AdoptionLikelihood').head(4).index.tolist()\n\nif len(top_features) >= 2:\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    axes = axes.ravel()\n    \n    for idx, feature in enumerate(top_features[:4]):\n        # Scatter plot\n        for adoption_status in [0, 1]:\n            mask = df['AdoptionLikelihood'] == adoption_status\n            label = 'Adopted' if adoption_status == 1 else 'Not Adopted'\n            color = '#2ecc71' if adoption_status == 1 else '#e74c3c'\n            axes[idx].scatter(df[mask][feature], df[mask]['AdoptionLikelihood'],\n                            alpha=0.5, s=30, label=label, color=color)\n        \n        axes[idx].set_xlabel(feature, fontsize=11, fontweight='bold')\n        axes[idx].set_ylabel('AdoptionLikelihood', fontsize=11, fontweight='bold')\n        axes[idx].set_title(f'{feature} vs AdoptionLikelihood (r={target_corr[feature]:.3f})',\n                           fontsize=12, fontweight='bold', pad=10)\n        axes[idx].legend()\n        axes[idx].grid(alpha=0.3, linestyle='--')\n    \n    plt.tight_layout()\n    plt.show()\n\nprint(\"\\n\" + \"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "w1gkqpys33a",
   "source": "### 4.4 Correlation Analysis",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "sjozz52wvs",
   "source": "#### 4.3.2 Numerical Features by Target (Boxplots)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "u1fddu2nsqp",
   "source": "# Adoption rate by categorical features\nall_features = ['PetType', 'Breed', 'Color', 'Size', 'Vaccinated', 'HealthCondition', 'PreviousOwner']\n\nprint(\"=\"*70)\nprint(\"ADOPTION RATE BY CATEGORICAL FEATURES\")\nprint(\"=\"*70)\n\n# Calculate adoption rates\noverall_adoption_rate = df['AdoptionLikelihood'].mean()\nprint(f\"\\nOverall Adoption Rate: {overall_adoption_rate:.2%}\")\nprint(\"-\"*70)\n\n# Statistics for each feature\nfor feature in all_features:\n    print(f\"\\n{feature}:\")\n    adoption_by_feature = df.groupby(feature)['AdoptionLikelihood'].agg(['mean', 'count'])\n    adoption_by_feature.columns = ['Adoption Rate', 'Count']\n    adoption_by_feature['Adoption Rate'] = adoption_by_feature['Adoption Rate'] * 100\n    print(adoption_by_feature.round(2))\n\n# Visualizations\nfig, axes = plt.subplots(3, 3, figsize=(20, 16))\naxes = axes.ravel()\n\nfor idx, feature in enumerate(all_features):\n    if idx < len(axes):\n        adoption_by_feature = df.groupby(feature)['AdoptionLikelihood'].mean().sort_values(ascending=False)\n        \n        # Create bar chart\n        bars = axes[idx].bar(range(len(adoption_by_feature)), \n                            adoption_by_feature.values * 100,\n                            color='#2ecc71', edgecolor='black', linewidth=1.5, alpha=0.8)\n        \n        axes[idx].set_xlabel(feature, fontsize=12, fontweight='bold')\n        axes[idx].set_ylabel('Adoption Rate (%)', fontsize=12, fontweight='bold')\n        axes[idx].set_title(f'Adoption Rate by {feature}', fontsize=13, fontweight='bold', pad=10)\n        axes[idx].set_xticks(range(len(adoption_by_feature)))\n        axes[idx].set_xticklabels(adoption_by_feature.index, rotation=45, ha='right')\n        axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n        \n        # Add horizontal line for overall mean\n        axes[idx].axhline(y=overall_adoption_rate * 100, color='red', linestyle='--',\n                         linewidth=2, label=f'Overall: {overall_adoption_rate*100:.1f}%')\n        \n        # Add percentage labels on bars\n        for bar in bars:\n            height = bar.get_height()\n            axes[idx].text(bar.get_x() + bar.get_width()/2., height,\n                          f'{height:.1f}%',\n                          ha='center', va='bottom', fontsize=9, fontweight='bold')\n        \n        axes[idx].legend(loc='upper right')\n\n# Remove extra subplots\nfor idx in range(len(all_features), len(axes)):\n    fig.delaxes(axes[idx])\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e4899umk13r",
   "source": "## 6. Data Cleaning and Feature Engineering",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "8m8f5e0y1l3",
   "source": "### 6.1 Handle Missing Values and Duplicates",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "qpno3znj4uh",
   "source": "# Create a copy for cleaning\ndf_clean = df.copy()\n\nprint(\"Initial dataset shape:\", df_clean.shape)\n\n# Handle duplicates\nduplicates = df_clean.duplicated().sum()\nif duplicates > 0:\n    print(f\"Removing {duplicates} duplicate rows...\")\n    df_clean = df_clean.drop_duplicates()\nelse:\n    print(\"No duplicates found.\")\n\n# Handle missing values\nmissing = df_clean.isnull().sum().sum()\nif missing > 0:\n    print(f\"\\nHandling {missing} missing values...\")\n    # Strategy: fill numerical with median, categorical with mode\n    for col in df_clean.columns:\n        if df_clean[col].isnull().sum() > 0:\n            if df_clean[col].dtype == 'object':\n                df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n            else:\n                df_clean[col].fillna(df_clean[col].median(), inplace=True)\nelse:\n    print(\"No missing values found.\")\n\nprint(\"\\nCleaned dataset shape:\", df_clean.shape)\nprint(\"Missing values after cleaning:\", df_clean.isnull().sum().sum())",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:03:26.139263Z",
     "start_time": "2025-12-05T11:03:26.129719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (2007, 13)\n",
      "No duplicates found.\n",
      "No missing values found.\n",
      "\n",
      "Cleaned dataset shape: (2007, 13)\n",
      "Missing values after cleaning: 0\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "f62rozseuu5",
   "source": "### 6.2 Handle Outliers",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "eoiz9iczc2f",
   "source": "# Detect and handle outliers using IQR method\ndef detect_outliers_iqr(data, column):\n    Q1 = data[column].quantile(0.25)\n    Q3 = data[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n    return outliers, lower_bound, upper_bound\n\nnumerical_features = ['AgeMonths', 'WeightKg', 'TimeInShelterDays', 'AdoptionFee']\n\nprint(\"Outlier Detection Summary:\")\nprint(\"=\"*50)\nfor col in numerical_features:\n    outliers, lower, upper = detect_outliers_iqr(df_clean, col)\n    print(f\"\\n{col}:\")\n    print(f\"  Outliers found: {len(outliers)}\")\n    print(f\"  Lower bound: {lower:.2f}, Upper bound: {upper:.2f}\")\n    \n# For now, we'll keep outliers but note them\n# In production, you might want to cap or remove them based on domain knowledge\nprint(\"\\n\\nNote: Outliers are kept in the dataset for now.\")\nprint(\"Consider capping or removing them based on domain expertise.\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:03:29.006101Z",
     "start_time": "2025-12-05T11:03:28.994988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Detection Summary:\n",
      "==================================================\n",
      "\n",
      "AgeMonths:\n",
      "  Outliers found: 0\n",
      "  Lower bound: -87.00, Upper bound: 273.00\n",
      "\n",
      "WeightKg:\n",
      "  Outliers found: 0\n",
      "  Lower bound: -12.28, Upper bound: 43.75\n",
      "\n",
      "TimeInShelterDays:\n",
      "  Outliers found: 0\n",
      "  Lower bound: -46.50, Upper bound: 133.50\n",
      "\n",
      "AdoptionFee:\n",
      "  Outliers found: 0\n",
      "  Lower bound: -245.00, Upper bound: 747.00\n",
      "\n",
      "\n",
      "Note: Outliers are kept in the dataset for now.\n",
      "Consider capping or removing them based on domain expertise.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "jwz08s26esh",
   "source": "### 6.3 Feature Engineering",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "df89u8ok8tg",
   "source": "# Create new features\n# Check if df_clean exists, if not create it from df\nif 'df_clean' not in dir():\n    df_clean = df.copy()\n    print(\"Note: df_clean created from df (cleaning steps not run)\")\n\ndf_engineered = df_clean.copy()\n\n# 1. Age categories\ndef categorize_age(age):\n    if age < 12:\n        return 'Young'\n    elif age < 60:\n        return 'Adult'\n    else:\n        return 'Senior'\n\ndf_engineered['AgeCategory'] = df_engineered['AgeMonths'].apply(categorize_age)\n\n# 2. Weight categories based on size\ndf_engineered['WeightPerSize'] = df_engineered['WeightKg'] / df_engineered['Size'].map({'Small': 1, 'Medium': 2, 'Large': 3})\n\n# 3. Shelter time categories\ndef categorize_shelter_time(days):\n    if days < 30:\n        return 'Short'\n    elif days < 90:\n        return 'Medium'\n    else:\n        return 'Long'\n\ndf_engineered['ShelterTimeCategory'] = df_engineered['TimeInShelterDays'].apply(categorize_shelter_time)\n\n# 4. Fee range categories\ndf_engineered['FeeRange'] = pd.cut(df_engineered['AdoptionFee'], bins=3, labels=['Low', 'Medium', 'High'])\n\n# 5. Health score (combination of vaccination and health condition)\ndf_engineered['HealthScore'] = df_engineered['Vaccinated'] + df_engineered['HealthCondition']\n\n# 6. Age in years\ndf_engineered['AgeYears'] = df_engineered['AgeMonths'] / 12\n\nprint(\"New Features Created:\")\nprint(\"=\"*50)\nprint(\"1. AgeCategory - Categorical age groups\")\nprint(\"2. WeightPerSize - Weight normalized by size\")\nprint(\"3. ShelterTimeCategory - Time in shelter categories\")\nprint(\"4. FeeRange - Adoption fee ranges\")\nprint(\"5. HealthScore - Combined health indicator\")\nprint(\"6. AgeYears - Age in years\")\n\nprint(f\"\\nNew dataset shape: {df_engineered.shape}\")\nprint(f\"\\nSample of engineered features:\")\ndf_engineered[['AgeMonths', 'AgeCategory', 'AgeYears', 'WeightKg', 'WeightPerSize', \n               'TimeInShelterDays', 'ShelterTimeCategory', 'HealthScore']].head()",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:03:31.972514Z",
     "start_time": "2025-12-05T11:03:31.952614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Features Created:\n",
      "==================================================\n",
      "1. AgeCategory - Categorical age groups\n",
      "2. WeightPerSize - Weight normalized by size\n",
      "3. ShelterTimeCategory - Time in shelter categories\n",
      "4. FeeRange - Adoption fee ranges\n",
      "5. HealthScore - Combined health indicator\n",
      "6. AgeYears - Age in years\n",
      "\n",
      "New dataset shape: (2007, 19)\n",
      "\n",
      "Sample of engineered features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   AgeMonths AgeCategory   AgeYears   WeightKg  WeightPerSize  \\\n",
       "0        131      Senior  10.916667   5.039768       1.679923   \n",
       "1         73      Senior   6.083333  16.086727       5.362242   \n",
       "2        136      Senior  11.333333   2.076286       1.038143   \n",
       "3         97      Senior   8.083333   3.339423       3.339423   \n",
       "4        123      Senior  10.250000  20.498100       6.832700   \n",
       "\n",
       "   TimeInShelterDays ShelterTimeCategory  HealthScore  \n",
       "0                 27               Short            1  \n",
       "1                  8               Short            0  \n",
       "2                 85              Medium            0  \n",
       "3                 61              Medium            0  \n",
       "4                 28               Short            0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>AgeYears</th>\n",
       "      <th>WeightKg</th>\n",
       "      <th>WeightPerSize</th>\n",
       "      <th>TimeInShelterDays</th>\n",
       "      <th>ShelterTimeCategory</th>\n",
       "      <th>HealthScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>Senior</td>\n",
       "      <td>10.916667</td>\n",
       "      <td>5.039768</td>\n",
       "      <td>1.679923</td>\n",
       "      <td>27</td>\n",
       "      <td>Short</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>Senior</td>\n",
       "      <td>6.083333</td>\n",
       "      <td>16.086727</td>\n",
       "      <td>5.362242</td>\n",
       "      <td>8</td>\n",
       "      <td>Short</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136</td>\n",
       "      <td>Senior</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>2.076286</td>\n",
       "      <td>1.038143</td>\n",
       "      <td>85</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>Senior</td>\n",
       "      <td>8.083333</td>\n",
       "      <td>3.339423</td>\n",
       "      <td>3.339423</td>\n",
       "      <td>61</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123</td>\n",
       "      <td>Senior</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>20.498100</td>\n",
       "      <td>6.832700</td>\n",
       "      <td>28</td>\n",
       "      <td>Short</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "oh1r40tka4n",
   "source": "### 6.4 Encode Categorical Variables",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "xuabh8vlat8",
   "source": "# Encode categorical variables\n# Check if df_engineered exists, if not create it from df_clean or df\nif 'df_engineered' not in dir():\n    if 'df_clean' in dir():\n        print(\"Warning: df_engineered not found. Run the Feature Engineering cell first!\")\n        print(\"Creating df_engineered from df_clean without feature engineering...\")\n        df_engineered = df_clean.copy()\n    else:\n        print(\"Warning: Both df_engineered and df_clean not found. Run previous cells first!\")\n        print(\"Creating from df...\")\n        df_engineered = df.copy()\n\ndf_encoded = df_engineered.copy()\n\n# One-hot encoding for nominal categorical variables\nnominal_features = ['PetType', 'Breed', 'Color', 'Size']\n\n# Add engineered features if they exist\nif 'AgeCategory' in df_encoded.columns:\n    nominal_features.extend(['AgeCategory', 'ShelterTimeCategory', 'FeeRange'])\n\n# Apply one-hot encoding\ndf_encoded = pd.get_dummies(df_encoded, columns=nominal_features, prefix=nominal_features, drop_first=True)\n\nprint(\"Encoding Summary:\")\nprint(\"=\"*50)\nprint(f\"Original shape: {df_engineered.shape}\")\nprint(f\"After encoding shape: {df_encoded.shape}\")\nprint(f\"\\nNew columns added: {df_encoded.shape[1] - df_engineered.shape[1]}\")\n\nprint(\"\\nFirst few columns after encoding:\")\nprint(df_encoded.columns.tolist()[:20])",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:03:44.512822Z",
     "start_time": "2025-12-05T11:03:44.503903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Summary:\n",
      "==================================================\n",
      "Original shape: (2007, 19)\n",
      "After encoding shape: (2007, 32)\n",
      "\n",
      "New columns added: 13\n",
      "\n",
      "First few columns after encoding:\n",
      "['PetID', 'AgeMonths', 'WeightKg', 'Vaccinated', 'HealthCondition', 'TimeInShelterDays', 'AdoptionFee', 'PreviousOwner', 'AdoptionLikelihood', 'WeightPerSize', 'HealthScore', 'AgeYears', 'PetType_Cat', 'PetType_Dog', 'PetType_Rabbit', 'Breed_Labrador', 'Breed_Parakeet', 'Breed_Persian', 'Breed_Poodle', 'Breed_Rabbit']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "neoic6j4az",
   "source": "### 6.5 Prepare Final Dataset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "or0to3fpi4i",
   "source": "# Prepare final dataset for modeling\ndf_final = df_encoded.copy()\n\n# Drop PetID as it's just an identifier\nif 'PetID' in df_final.columns:\n    df_final = df_final.drop('PetID', axis=1)\n\n# Separate features and target\nX = df_final.drop('AdoptionLikelihood', axis=1)\ny = df_final['AdoptionLikelihood']\n\nprint(\"Final Dataset Summary:\")\nprint(\"=\"*50)\nprint(f\"Features shape: {X.shape}\")\nprint(f\"Target shape: {y.shape}\")\nprint(f\"\\nNumber of features: {X.shape[1]}\")\nprint(f\"\\nTarget distribution:\")\nprint(y.value_counts())\nprint(f\"\\nClass balance: {y.value_counts(normalize=True) * 100}\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Data preparation complete!\")\nprint(\"Dataset is ready for model training.\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:03:47.857170Z",
     "start_time": "2025-12-05T11:03:47.848376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataset Summary:\n",
      "==================================================\n",
      "Features shape: (2007, 30)\n",
      "Target shape: (2007,)\n",
      "\n",
      "Number of features: 30\n",
      "\n",
      "Target distribution:\n",
      "AdoptionLikelihood\n",
      "0    1348\n",
      "1     659\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class balance: AdoptionLikelihood\n",
      "0    67.164923\n",
      "1    32.835077\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "==================================================\n",
      "Data preparation complete!\n",
      "Dataset is ready for model training.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "8tl7v67dk5n",
   "source": "### 6.6 Save Processed Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "7z4ni00wllp",
   "source": "# Save processed datasets for future use\n# Uncomment the lines below to save the processed data\n\n# df_clean.to_csv('pet_adoption_cleaned.csv', index=False)\n# df_engineered.to_csv('pet_adoption_engineered.csv', index=False)\n# df_final.to_csv('pet_adoption_final.csv', index=False)\n\nprint(\"Processed datasets ready to be saved:\")\nprint(\"1. df_clean - Cleaned data (duplicates and missing values handled)\")\nprint(\"2. df_engineered - With engineered features\")\nprint(\"3. df_final - Fully processed and encoded, ready for modeling\")\nprint(\"\\nUncomment the save commands above to export the data.\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:03:51.003807Z",
     "start_time": "2025-12-05T11:03:51.000965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed datasets ready to be saved:\n",
      "1. df_clean - Cleaned data (duplicates and missing values handled)\n",
      "2. df_engineered - With engineered features\n",
      "3. df_final - Fully processed and encoded, ready for modeling\n",
      "\n",
      "Uncomment the save commands above to export the data.\n"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}